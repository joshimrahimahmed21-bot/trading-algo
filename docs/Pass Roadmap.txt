Forward Development Roadmap (Pass 17+ Plan)
With the foundation built up through Pass 16.5, the final development passes will focus on integrating the advanced signal processing (relativity and decay), refining regime logic, and preparing the strategy for robust real-world performance. Below is the roadmap for the upcoming passes, expanding on the initial plan (Pass 17–20) with our latest objectives:
17. Pass 17: Signal Relativity Integration & Multi-Contract Validation – This pass will implement the Relativity and Decay nodes for PosVol and momentum signals and simultaneously ensure the multi-contract features work as expected under these new conditions. We will develop the normalization (Relativity) node to compute rolling statistics for key inputs (likely using a RollingStats class or similar with a long lookback) and produce Z-scores or percentile ranks. In tandem, we add a Decay node that maintains an exponentially decaying average of the signal. Concretely, for PosVol: after computing lastQ_PosVol_Proxy each bar, we will normalize it (e.g. Q_PosVol_Z = (Proxy - μ)/σ clamped to a reasonable range) and then feed that into a decay filter M. If enabled, the strategy might use Q_PosVol_Decay in place of or in addition to the raw proxy in its composite score. We’ll introduce new parameters such as RelativityPeriod (for the rolling mean/std window or EWMA alpha) and DecayRate/DecayBlend (for how fast the EWMA decays and how much weight to give recent vs memory). Similarly, for momentum, we’ll decide whether to apply this to the TrueMomo final output or separately to its components (BaseMomo and FavMomo). A likely approach is to normalize both base price momentum (e.g. RSI or other measure) and volume-influenced momentum, then compute TrueMomo from those normalized values. By the end of Pass 17, the code will have these nodes wired in behind feature flags (so we can turn them off to compare).
In parallel, we’ll use this pass to validate multi-contract behavior thoroughly. After wiring relativity, we will run backtests with various BaseContracts values (1, 2, 5, maybe 10 if performance allows) to ensure that all trade logs, PnL calculations, and exits behave correctly. This includes checking that the CORE/Runner split logic properly allocates quantities (e.g. if BaseContracts=5, does it split 3 and 2? and if so, are those logged correctly and exits handled?). We also verify no regression in single-contract mode (BaseContracts=1 should function exactly like prior single-position logic). Any bugs (for example, if we find an off-by-one contract error or a scenario where runner wasn’t placed due to a rounding issue) will be fixed in this pass. Essentially, Pass 17 combines the feature development of relativity with the testing of the sizing – since the relativity doesn’t heavily interact with order execution, these can be done in tandem and it keeps our momentum going.
•	Expected outcome: PosVol and momentum signals are now “regime-aware” via normalization and have memory via decay. Multi-contract trades execute flawlessly for different sizes. We’ll likely keep relativity/decay off until Pass 18’s tuning, but the scaffolding is in place.
18. Pass 18: Regime Detection & Adaptive Trade Management – In this pass, we focus on making the strategy adaptive to market regimes. First, we will implement an automatic regime classification using our existing and new indicators. For example, we may define: “Trend regime” when ADX > 25 and ATR percentile is above 50th (meaning moderately volatile and directional), “LowVol chop regime” when ATR is below a threshold and ADX < 20 (low volatility, sideways), and perhaps a “High Volatility” regime when ATR is very high regardless of ADX (volatile breakout conditions). These definitions will be refined by testing different combinations and possibly using clustering on historical data. We will use the UseRegimes flag to turn this on, and the strategy will update an ActiveRegime variable (likely an enum or int internally, even if we output a string for readability) each bar or each day. We will also incorporate hysteresis using HysteresisBarsParam – e.g., require a regime’s conditions to hold for N consecutive bars before switching, and maybe prevent flip-flopping too fast by imposing a minimum time in a regime.
Once regime detection is in place, the second part of this pass is to adjust trade management parameters based on the active regime. We will create a mapping of regime -> parameters. Concretely, we might introduce a few sets of presets: - Trend Regime: allow runner (ApplyRunnerManagement = true), set runner profit target farther (we could increase the runnerR calculation or even leave RunnerMaxBars = 0 for no time limit), possibly lower MinQTotal2 threshold (to take more trades, assuming trend gives a tailwind). - Range/Chop Regime: perhaps disable runner (ApplyRunnerManagement = false or force allowRunner = false even if size >=2), or if we keep runner, use a very tight RunnerMaxBars (e.g. exit after 5 bars if not hit target), and raise MinQTotal2 (so only very high-quality mean reversion trades are taken). Also, possibly tighten stop distance in this regime to cut losers quickly. - Volatile Breakout Regime: if we identify a high volatility state, we might do something like only take trades aligned with momentum (demand higher momentum score), and use wider stops with smaller position size (or even skip if too volatile). Since position sizing in NT is fixed per run, we might simulate dynamic sizing by not trading every signal in high volatility unless very high quality, effectively reducing trade frequency instead of contract count.
Implementing these adaptations will require adding logic in the entry and/or in the OnBarUpdate after computing metrics. For example, after determining regime, we can on-the-fly adjust our internal parameters like MinQTotal2 or set a flag to ignore runner. One straightforward method: inside UpdateEntrySignals() or just before arming a trade, check the regime and if (regime == RangeBound) then allowRunner=false or override RunnerMomoThreshold to a very high value to effectively block runner. Similarly, we can adjust the profit target for core in trending regime by maybe using a different multiple (though core is fixed at 1R by design; any variation here might be more in terms of letting runner handle the extended profit). We need to be cautious and test these – changing strategy parameters on the fly can confuse the Strategy Analyzer’s performance stats (since it expects static rules), but since we’re not optimizing the regime logic itself initially, it should be fine for backtesting. We will thoroughly log regime changes and which trades used which settings, to verify it’s working.
Additionally, in Pass 18 we will finalize the Volume Profile integration alongside regime logic. The reasoning is that volume profile information can itself be used to identify regimes (e.g. if price is within a high-volume node, that’s typically a ranging market; if price is in a low-volume area moving to another node, that’s trending or breakaway). So integrating the actual VP indicator here will assist both our regime classification and provide immediate benefit to trade filtering. We’ll connect a Volume Profile indicator that gives us metrics like “distance to nearest high-volume node” or a score for tailwind/headwind. If it’s too complex to integrate fully, we might start simpler: e.g., use daily volume profile to see if current price is above or below the day’s Point of Control (POC) to classify environment. In any case, by end of this pass, the strategy should be making smarter decisions based on context: it will know if we’re chopping or trending and adjust how it trades (and possibly what signals are emphasized, like favoring volume signals more in chop, momentum in trend).
•	Expected outcome: The strategy dynamically toggles trade management rules according to regime. Volume Profile data is now feeding in and perhaps contributing to those regime decisions or directly filtering entries (e.g., skip longs into volume resistance). We will likely see in logs entries like “Regime: Trend – using runner” vs “Regime: Range – core-only trade” to confirm it. This sets the stage for optimizing these new conditions.
19. Pass 19: Extensive Parameter Tuning & Optimization – After adding significant new capabilities, Pass 19 is dedicated to testing and tuning the strategy to its optimal settings. Using NinjaTrader’s Strategy Analyzer (and possibly external tools for Monte Carlo), we will conduct multi-dimensional sweeps of the parameters: - We will tune the new Relativity/Decay parameters: e.g. the decay factor α (half-life), the blend β between immediate signal and decayed memory, and the window length or EWMA span for normalization. The goal is to see if, for instance, a 50-bar lookback vs 200-bar lookback for Z-score produces better Sharpe or higher win rate. We expect these to have a noticeable effect on how the strategy adapts to changing conditions (short lookback = very responsive but maybe noisy, long = stable but could miss regime shifts). - Quality Thresholds: Optimize MinQTotal2 and any individual weights (W_PosVolProxy, W_TrueMomo, etc.) to find an ideal balance. Now that PosVol and Momo are improved, their weights might be set >0 by default. We’ll run scenarios to see how performance varies if, say, PosVol is highly weighted vs not at all. This will also inform if our new signals truly add value. The optimization process may highlight that some features are redundant – for example, if regime filtering is effective, the volatility filter might no longer add much, and could be left off. - Regime Logic Parameters: We will also vary the criteria for regime classification (if they are exposed or easily adjustable). Perhaps we make the ADX threshold or ATR percentile threshold configurable and test different splits. The HysteresisBarsParam will definitely be tested (to ensure we don’t whipsaw the regime – likely we’ll find a moderate value like 5 or 10 bars delay is needed to avoid oscillation on one-bar noise). - Volume Profile Usage: Now that real VP signals are in play, we’ll examine their impact. For example, optimize the coefficients VP_RunnerK1Param and VP_RunnerK2Param which control how much to adjust runnerPct each bar with tailwind/headwind. This could reveal whether an aggressive adjustment (e.g. K1=0.5) yields better results or if minimal adjustment (K1=0.1) is preferable. Similarly, if we introduced any explicit VP-based entry filter (like “skip if headwind > X”), we’d test the threshold X. - Risk/Return Trade-offs: We will look not just at profit metrics but also drawdowns and consistency. This is where we incorporate Monte Carlo simulations of the equity curve – by randomizing trade order or bootstrapping results, we’ll gauge the probability of large drawdowns. If the optimized parameters that give highest profit also incur intolerable drawdowns, we may dial them back. For instance, the optimizer might find a very low MinQTotal2 (allow many trades) gives best net profit, but Monte Carlo shows it increases risk of ruin. We would then choose a slightly more selective setting to reduce risk. This process is somewhat subjective but important for aligning with prop firm risk limits (e.g., ensure max peak-to-valley drawdown stays below a certain threshold so it wouldn’t blow a funded account).
Technically, this pass will involve a lot of batch runs. We might use the built-in optimizer for smaller subsets at a time (due to performance concerns as noted). We’ll likely iterate: first do a broad sweep coarsely to identify general areas, then fine-tune around the promising values. It’s possible we’ll employ a few Walk-Forward Optimizations (WFO) to see if parameters remain stable across periods – a good check against overfitting. We’ll also test on different market conditions (e.g. recent bullish trend vs earlier choppy period) to ensure the strategy adapts as intended. If the regime mechanism works, we should see the strategy naturally handle both conditions well with one parameter set.
•	Expected outcome: A well-tuned strategy with updated default parameters that make sense given all new features. By the end of Pass 19, we aim to have evidence-backed confidence in the settings: e.g. “Decay half-life = 50 bars and β=0.7 (favor current data 70%, memory 30%) gave the best balance”, “MinQTotal2 = 0.6 filters out bad trades without cutting good ones”, “RunnerMomoThreshold ~ 0.3 and RunnerSpaceThreshold ~ 0.5 ensure runners only in strong conditions, which improved win rate” – etc. We’ll compile these results and likely update the documentation (like this summary and the handbook) with the rationale for chosen values.
20. Pass 20: Final Refactoring, Risk Management & Deployment Prep – This final official pass is about making the strategy production-ready. We will do a thorough code review and refactoring where needed: - Remove any debug code or commented-out snippets that are no longer needed. Ensure all TODOs from prior passes are resolved or clearly marked for future. - Double-check thread-safety and performance: although NT strategies run on the single thread for OnBarUpdate, things like file writing or indicator access should still be checked. We’ll confirm that our logging flushes files properly and doesn’t leave them open. Since we log on every trade/exit, ensure that doesn’t lag in live (in backtest it’s fine; in live, heavy disk writing can slow down real-time processing). We might implement a simple rate limit or batch for logging if needed. - Dynamic Risk Module: If feasible, we will implement an optional dynamic position sizing logic for live trading. One approach is to adjust BaseContracts based on recent performance – for example, a rudimentary algorithm: if the account grows by 10%, increase BaseContracts by 1 (and conversely decrease if a drawdown of X% occurs). This can be external (trader’s discretion) or internal. If internal, we can tie it to equity curve logging – since we already track equity in RunInfo or can compute it, we can decide at certain checkpoints to change a parameter. However, NinjaTrader’s live strategy interface doesn’t allow changing a parameter without stopping/restarting the strategy. So this might be more of a guideline for the user rather than automated. We will likely document how to scale up or down safely (e.g. only do so when flat, and re-enable strategy with new BaseContracts). - Kill-Switches: Implement hard stops for abnormal conditions. For example, if for some reason the strategy takes N consecutive losses beyond a threshold (could indicate market regime outside its scope, or a bug), it could halt itself. We can track a rolling count of losses or a drawdown from peak equity (we have equity info from logs). NinjaTrader doesn’t provide a built-in auto-disable on strategy side, but we can simulate it by not executing new trades when a condition is met. A simple kill-switch might be: if drawdown > Y (or if last 10 trades all lost), set a flag SuspendTrading = true and skip any new entries until manually reset. This protects against tail-risk or a structural break the strategy isn’t built for. We’ll include parameters for this (e.g. MaxDrawdownPercent or MaxLosingStreak) so it’s configurable. - Final Live Testing: Before deployment, we will run the strategy in Market Replay or a Sim account in real-time conditions for a period (at least several days spanning different sessions). This is to ensure that all the moving parts (especially those that can’t be fully verified in backtest, like realtime order submission timing, or any intrabar behavior) work smoothly. We’ll pay attention to things like: Are there any order rejections? (e.g. if an entry and exit happen on the same bar, NinjaTrader might reject if not handled right – though our design avoids that by using breakout entries.) Does the strategy recover gracefully from a disconnect or restart (our logging system creates new files each run – make sure it doesn’t overwrite or cause an exception if run twice in one day)? These practical considerations are part of hardening. - Documentation & Handover: We will update all user-facing descriptions (the property Display names and tooltips) to reflect the final functionality. Any parameters that ended up not useful will be noted or removed if they complicate things. The code comments will be cleaned up to match what the strategy actually does (since early passes left some comments about intended features that evolved, we’ll reconcile those with reality).
After Pass 20, the MNQRSTest strategy should be fully ready for live deployment on micro NASDAQ or a similar instrument. It will have adaptive qualities to handle different market regimes, robust logging for monitoring, and safety mechanisms to protect the account. The expectation is that by following this roadmap, we’ve gradually built a strategy that is not only effective in historical testing but also reliable and manageable in production.
Current Status: We are entering Pass 17, focusing on wiring in relativity/decay and finalizing multi-contract support. The momentum going forward is strong – a lot of the conceptual heavy lifting (designing how to normalize and decay signals, how to classify regimes) has been done, and initial testing suggests these additions can significantly improve performance by adjusting the strategy to context. The next steps will be intensive, but by the end of them, we aim to have a strategy that we can confidently trade and potentially scale up. The “final stretch” – Monte Carlo risk analysis and tailoring to prop trading constraints – will ensure that when we go live, we do so with appropriate risk management, increasing the odds of long-term survival and success for the strategy. Let’s execute these remaining passes and get to deployment!
